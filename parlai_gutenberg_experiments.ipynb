{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicolay-r/deep-book-processing/blob/master/parlai_gutenberg_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1ktkLcs4NUp"
      },
      "outputs": [],
      "source": [
        "# select python version\n",
        "!sudo apt-get install python3.8 --fix-missing\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1\n",
        "!sudo update-alternatives --config python3\n",
        "# check python version\n",
        "!python --version\n",
        "# install pip for new python\n",
        "!sudo apt-get install python3.8-distutils\n",
        "!wget https://bootstrap.pypa.io/pip/get-pip.py\n",
        "!sudo python get-pip.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "us6pny_Zsql9",
        "outputId": "e6bc3650-515c-4a07-914e-1966b2b74d8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.8.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-QGeENzUbyT"
      },
      "outputs": [],
      "source": [
        "!rm -rf parlai_bookchar_task\n",
        "!git clone https://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@github.com/nicolay-r/parlai_bookchar_task.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Z4RITZaQ1rg"
      },
      "outputs": [],
      "source": [
        "!pip install parlai pytorch-pretrained-bert\n",
        "# Install py-rouge metrics\n",
        "!pip install py-rouge\n",
        "!python -c \"import nltk; nltk.download('punkt')\"\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9l435Ob00Y5"
      },
      "outputs": [],
      "source": [
        "!rm -rf \"/usr/local/lib/python3.10/dist-packages/data/GutenbertBookChars\"\n",
        "!cd parlai_bookchar_task && ./setup_colab.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-QJKL6cS2Nw",
        "outputId": "6951bbf2-cfac-49be-97e4-947606c2a6a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r gdrive/MyDrive/work-NewCastle/my-studies/dataset-v4/parlai/* ./parlai/\n",
        "#!cp -r gdrive/MyDrive/work-NewCastle/my-studies/dataset-v4.1/parlai/* ./parlai/"
      ],
      "metadata": {
        "id": "EqEbfazY_Tzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-PZVWYumbk1"
      },
      "source": [
        "This is a **BERT-Bi-Ranker** application.\n",
        "\n",
        "It is supposed to be pretrained first on the ConvAI2 data!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nb-GA7iiVmb2"
      },
      "outputs": [],
      "source": [
        "!parlai train_model -t gutenbergbookchars -m bert_ranker/bi_encoder_ranker --batchsize 20 -veps 1 --num-epochs 10 \\\n",
        "--save-after-valid True --log_every_n_steps 500 --tensorboard_log True --model_file ./parlai_bert/bert_biencoder_test --fp16 True --truncate 360 \\\n",
        "--candidates batch --dict-tokenizer bpe --dict-lower True --history-size -1 --optimizer adam -lr 5e-05 --data-parallel True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPnVaS6amjHi"
      },
      "source": [
        "Random selection application"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2d1YrncXmmHJ"
      },
      "outputs": [],
      "source": [
        "!parlai eval_model -m random_candidate -t gutenbergbookchars:Spectrum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Li4Sncqxmy3z"
      },
      "source": [
        "Mem neural network application\n",
        "`-mf` denotes the **model file** to load/save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGl_-Kunm1kb"
      },
      "outputs": [],
      "source": [
        "!parlai train_model -m memnn -t gutenbergbookchars --model_file ./parlai/memnn-origin -veps 1 -eps 20 \\\n",
        "--save-after-valid True --log_every_n_steps 5000 --tensorboard_log True --batchsize 128 -lr 2 \\\n",
        "  --dynamic-batching full --truncate 320"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jiR-p-KpXD1a"
      },
      "outputs": [],
      "source": [
        "!parlai train_model -m memnn --init-model ./parlai/memnn-origin  -t gutenbergbookchars:Spectrum --model_file ./parlai/memnn-spectrum -veps 1 -eps 20 \\\n",
        "--save-after-valid True --log_every_n_steps 5000 --tensorboard_log True --batchsize 128 -lr 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WYQLpSsv2z4u"
      },
      "outputs": [],
      "source": [
        "!parlai train_model -m tfidf_retriever -t gutenbergbookchars -mf ./parlai/gutenbertbookchars_tfidf \\\n",
        " -eps 1 --datatype train:ordered  --tensorboard_log True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c2llKlCdvko"
      },
      "source": [
        "# IR baseline\n",
        "\n",
        "**`NOTE:`**` the non-trained version is worse, so it is better to refer a pretrained zoo`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13R7v8fo5Y_R"
      },
      "outputs": [],
      "source": [
        "!parlai eval_model -m ir_baseline -t gutenbergbookchars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBopfgdRbGQS"
      },
      "outputs": [],
      "source": [
        "!parlai eval_model -m ir_baseline -t gutenbergbookchars -mf zoo:wikipedia_full/tfidf_retriever/model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1q6oGZg1eFJX"
      },
      "outputs": [],
      "source": [
        "!parlai eval_model -m ir_baseline -t gutenbergbookchars:Spectrum -mf zoo:wikipedia_full/tfidf_retriever/model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR-xCF-x-kCI"
      },
      "source": [
        "# IR-baseline model (dict)\n",
        "IR-baseline model, trained with the dict vocabulary.\n",
        "We limit the `-eps` to `5` according to the preliminary analysis here:\n",
        "https://docs.google.com/spreadsheets/d/1-_lJ-wfSlscyM1un1DdMw_xsuuD8U6GR_MmL1_iF0uY/edit#gid=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gYQwUQH5k6S"
      },
      "outputs": [],
      "source": [
        "!parlai train_model -m ir_baseline -t gutenbergbookchars \\\n",
        "  --dict-file ./parlai/gutenbergbookchars.dict -veps 1 -eps 5 \\\n",
        "  --model-file ./parlai/ir_baseline_dict --tensorboard_log True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!parlai train_model -m ir_baseline -t gutenbergbookchars:Spectrum \\\n",
        "  --init-model ./parlai/ir_baseline_dict \\\n",
        "  --dict-file ./parlai/gutenbergbookchars_spectrum.dict -veps 1 -eps 5 \\\n",
        "  --model-file ./parlai/ir_baseline_spectrum_dict --tensorboard_log True"
      ],
      "metadata": {
        "id": "b-NA8YVSOAV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!parlai eval_model -m ir_baseline -mf parlai/ir_baseline_dict -t gutenbergbookchars --metrics all"
      ],
      "metadata": {
        "id": "vu4kWO3WMkO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!parlai eval_model -m ir_baseline -mf parlai/ir_baseline_dict -t gutenbergbookchars:Spectrum --metrics all"
      ],
      "metadata": {
        "id": "-tYZOvAhPvlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!parlai eval_model -m ir_baseline -mf parlai/ir_baseline_spectrum_dict -t gutenbergbookchars:Spectrum --metrics all"
      ],
      "metadata": {
        "id": "FMWllJv_RCu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!parlai eval_model -m ir_baseline -mf parlai/ir_baseline_spectrum_dict -t gutenbergbookchars --metrics all"
      ],
      "metadata": {
        "id": "9lbGRtuSRoIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save content onto GDRIVE"
      ],
      "metadata": {
        "id": "2lmcZMcUXB0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cp -r /content/parlai/model_poly_* /content/gdrive/MyDrive/work-NewCastle/my-studies/dataset-v4.1/parlai/"
      ],
      "metadata": {
        "id": "IiKjROfYRyDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUmWFlhjB9HD"
      },
      "source": [
        "# Transformers\n",
        "\n",
        "ConvAI2 application of these models:\n",
        "To the certain extent correct, but we keep only information about persona\n",
        "without mentioning the exact type of the persona (at the moment, dataset v3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorrt"
      ],
      "metadata": {
        "id": "en36vCBSqf3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5IJQ8RQRBy63"
      },
      "outputs": [],
      "source": [
        "!parlai eval_model -mf zoo:pretrained_transformers/model_poly/model -t gutenbergbookchars \\\n",
        " --eval-candidates inline --batchsize 20 --text-truncate 360 --dynamic-batching full"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!parlai eval_model -mf zoo:pretrained_transformers/model_poly/model -t gutenbergbookchars:Spectrum \\\n",
        " --eval-candidates inline --batchsize 20  --text-truncate 360 --dynamic-batching full"
      ],
      "metadata": {
        "id": "RKvjgRdOp13J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDO5cxnkCO9h"
      },
      "outputs": [],
      "source": [
        "!parlai eval_model -mf zoo:pretrained_transformers/model_bi/model -t gutenbergbookchars:Spectrum \\\n",
        " --eval-candidates inline --batchsize 20 --text-truncate 360 --dynamic-batching full"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFbtEqoizDVQ"
      },
      "source": [
        "# Fine-tunning pretrained ConvAI2 models\n",
        "Fine-tunning model on the original dataset **without human level attributes**\n",
        "\n",
        "https://parl.ai/projects/polyencoder/\n",
        "\n",
        "Follow this tread in order to launch fine-tunning:\n",
        "\n",
        "https://github.com/facebookresearch/ParlAI/issues/2931"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugEZh4r1y5UF"
      },
      "outputs": [],
      "source": [
        "!parlai train_model \\\n",
        "    --init-model zoo:pretrained_transformers/model_bi/model \\\n",
        "    --batchsize 32 -t gutenbergbookchars \\\n",
        "    --model transformer/biencoder --eval-batchsize 6 \\\n",
        "    --warmup_updates 100 --lr-scheduler-patience 0 \\\n",
        "    --lr-scheduler-decay 0.4 -lr 5e-05 --data-parallel True \\\n",
        "    --history-size 20 --label-truncate 72 --text-truncate 360 \\\n",
        "    --num-epochs 3.0 --max_train_time 200000 -veps 0.5 -vme 8000 \\\n",
        "    --validation-metric accuracy --validation-metric-mode max \\\n",
        "    --save-after-valid True --log_every_n_secs 20 --candidates batch \\\n",
        "    --dict-tokenizer bpe --dict-lower True --optimizer adamax \\\n",
        "    --output-scaling 0.06 \\\n",
        "     --variant xlm --reduction-type mean --share-encoders False \\\n",
        "     --learn-positional-embeddings True --n-layers 12 --n-heads 12 \\\n",
        "     --ffn-size 3072 --attention-dropout 0.1 --relu-dropout 0.0 --dropout 0.1 \\\n",
        "     --n-positions 1024 --embedding-size 768 --activation gelu \\\n",
        "     --embeddings-scale False --n-segments 2 --learn-embeddings True \\\n",
        "     --share-word-embeddings False --dict-endtoken __start__ --fp16 True \\\n",
        "     --model-file ./parlai/model_bi_finetuned --tensorboard_log True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGQaUPrDgUNe"
      },
      "outputs": [],
      "source": [
        "!parlai train_model \\\n",
        "  --init-model zoo:pretrained_transformers/poly_model_huge_reddit/model \\\n",
        "  -t gutenbergbookchars \\\n",
        "  --model transformer/polyencoder --batchsize 20 --eval-batchsize 10 \\\n",
        "  --warmup_updates 100 --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 \\\n",
        "  -lr 5e-05 --data-parallel True --history-size 20 --label-truncate 72 \\\n",
        "  --text-truncate 360 --num-epochs 8.0 --max_train_time 200000 -veps 0.5 \\\n",
        "  -vme 8000 --validation-metric accuracy --validation-metric-mode max \\\n",
        "  --save-after-valid True --log_every_n_secs 20 --candidates batch --fp16 True \\\n",
        "  --dict-tokenizer bpe --dict-lower True --optimizer adamax --output-scaling 0.06 \\\n",
        "  --variant xlm --reduction-type mean --share-encoders False \\\n",
        "  --learn-positional-embeddings True --n-layers 12 --n-heads 12 --ffn-size 3072 \\\n",
        "  --attention-dropout 0.1 --relu-dropout 0.0 --dropout 0.1 --n-positions 1024 \\\n",
        "  --embedding-size 768 --activation gelu --embeddings-scale False --n-segments 2 \\\n",
        "  --learn-embeddings True --polyencoder-type codes --poly-n-codes 64 \\\n",
        "  --poly-attention-type basic --dict-endtoken __start__ \\\n",
        "  --model-file ./parlai/model_poly_finetuned --tensorboard_log True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJzx--sWVzDM"
      },
      "source": [
        "# Eval fine-tuned model on dataset with spectrums\n",
        "\n",
        "Important: mention version of the model with `.checkpoint`\n",
        "\n",
        "https://github.com/facebookresearch/ParlAI/issues/2904"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOdzhteMQd5H"
      },
      "outputs": [],
      "source": [
        "!parlai eval_model -mf ./parlai/model_bi_finetuned.checkpoint -t gutenbergbookchars:Spectrum \\\n",
        "  --eval-candidates inline --batchsize 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkLlS6OrWy77"
      },
      "outputs": [],
      "source": [
        "!parlai eval_model -mf ./parlai/model_poly_finetuned.checkpoint -t gutenbergbookchars:Spectrum \\\n",
        "  --eval-candidates inline --batchsize 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uqUMWPdTiYH"
      },
      "outputs": [],
      "source": [
        "!parlai train_model \\\n",
        "    --init-model ./parlai/model_bi_finetuned.checkpoint \\\n",
        "    --batchsize 32 -t gutenbergbookchars:Spectrum \\\n",
        "    --model transformer/biencoder --eval-batchsize 6 \\\n",
        "    --warmup_updates 100 --lr-scheduler-patience 0 \\\n",
        "    --lr-scheduler-decay 0.4 -lr 5e-05 --data-parallel True \\\n",
        "    --history-size 20 --label-truncate 72 --text-truncate 360 \\\n",
        "    --num-epochs 6.0 --max_train_time 200000 -veps 0.5 -vme 8000 \\\n",
        "    --validation-metric accuracy --validation-metric-mode max \\\n",
        "    --save-after-valid True --log_every_n_secs 20 --candidates batch \\\n",
        "    --dict-tokenizer bpe --dict-lower True --optimizer adamax \\\n",
        "    --output-scaling 0.06 \\\n",
        "     --variant xlm --reduction-type mean --share-encoders False \\\n",
        "     --learn-positional-embeddings True --n-layers 12 --n-heads 12 \\\n",
        "     --ffn-size 3072 --attention-dropout 0.1 --relu-dropout 0.0 --dropout 0.1 \\\n",
        "     --n-positions 1024 --embedding-size 768 --activation gelu \\\n",
        "     --embeddings-scale False --n-segments 2 --learn-embeddings True \\\n",
        "     --share-word-embeddings False --dict-endtoken __start__ --fp16 True \\\n",
        "     --model-file ./parlai/model_bi_spectrums_finetuned --tensorboard_log True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!parlai train_model \\\n",
        "  --init-model ./parlai/model_poly_finetuned.checkpoint \\\n",
        "  -t gutenbergbookchars \\\n",
        "  --model transformer/polyencoder --batchsize 20 --eval-batchsize 10 \\\n",
        "  --warmup_updates 100 --lr-scheduler-patience 0 --lr-scheduler-decay 0.4 \\\n",
        "  -lr 5e-05 --data-parallel True --history-size 20 --label-truncate 72 \\\n",
        "  --text-truncate 360 --num-epochs 8.0 --max_train_time 200000 -veps 0.5 \\\n",
        "  -vme 8000 --validation-metric accuracy --validation-metric-mode max \\\n",
        "  --save-after-valid True --log_every_n_secs 20 --candidates batch --fp16 True \\\n",
        "  --dict-tokenizer bpe --dict-lower True --optimizer adamax --output-scaling 0.06 \\\n",
        "  --variant xlm --reduction-type mean --share-encoders False \\\n",
        "  --learn-positional-embeddings True --n-layers 12 --n-heads 12 --ffn-size 3072 \\\n",
        "  --attention-dropout 0.1 --relu-dropout 0.0 --dropout 0.1 --n-positions 1024 \\\n",
        "  --embedding-size 768 --activation gelu --embeddings-scale False --n-segments 2 \\\n",
        "  --learn-embeddings True --polyencoder-type codes --poly-n-codes 64 \\\n",
        "  --poly-attention-type basic --dict-endtoken __start__ \\\n",
        "  --model-file ./parlai/model_poly_spectrums_finetuned --tensorboard_log True"
      ],
      "metadata": {
        "id": "Wk5IFkOOEdE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LFjFTriu7h5"
      },
      "outputs": [],
      "source": [
        "!parlai eval_model -mf ./parlai/model_bi_spectrums_finetuned.checkpoint -t gutenbergbookchars:Spectrum \\\n",
        "  --eval-candidates inline --batchsize 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AP-toGcOuEhd"
      },
      "source": [
        "Just in case, check what happens with this model when it is without traits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qu_-9Qk7uDKM"
      },
      "outputs": [],
      "source": [
        "!parlai eval_model -mf ./parlai/model_bi_spectrums_finetuned.checkpoint -t gutenbergbookchars --batchsize 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQzc99TBS7F4"
      },
      "source": [
        "# Generative Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FHvgHdzUbCV"
      },
      "source": [
        "### GPT-2 Small"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdhZmicuK2oR"
      },
      "outputs": [],
      "source": [
        "!parlai train_model -m hugging_face/gpt2 --add-special-tokens True \\\n",
        "--add-start-token True --gpt2-size small -t gutenbergbookchars -bs 24 \\\n",
        "-mf parlai/gpt-2-small-no-hla -veps 0.5 --tensorboard_log True --num-epochs 6 \\\n",
        " --fp16 True --text-truncate 360 --dynamic-batching full \\\n",
        " --validation-metric f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAGnFK0USqnZ"
      },
      "outputs": [],
      "source": [
        "!parlai train_model -m hugging_face/gpt2 --add-special-tokens True \\\n",
        "--add-start-token True --gpt2-size small -t gutenbergbookchars:Spectrum -bs 8 \\\n",
        "-mf parlai/gpt-2-small-spectrum -veps 0.5 --tensorboard_log True --num-epochs 6 \\\n",
        " --fp16 True --text-truncate 360 --dynamic-batching full \\\n",
        "--validation-metric f1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7HCwaInUMyZ"
      },
      "source": [
        "### GPT-2 Medium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwbL7ReXUPgN"
      },
      "outputs": [],
      "source": [
        "!parlai train_model -m hugging_face/gpt2 --add-special-tokens True \\\n",
        "--add-start-token True --gpt2-size medium -t gutenbergbookchars -bs 6 \\\n",
        "-mf parlai/gpt-2-medium-no-hla -veps 0.5 --tensorboard_log True --num-epochs 3 \\\n",
        " --sval True --fp16 True --text-truncate 360 --dynamic-batching full \\\n",
        " --validation-metric f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzUX_V1hUPWW"
      },
      "outputs": [],
      "source": [
        "!parlai train_model -m hugging_face/gpt2 --add-special-tokens True \\\n",
        "--add-start-token True --gpt2-size medium -t gutenbergbookchars:Spectrum -bs 6 \\\n",
        "-mf parlai/gpt-2-medium-spectrum -veps 0.5 --tensorboard_log True --num-epochs 2 \\\n",
        " --fp16 True --text-truncate 360 --dynamic-batching full \\\n",
        "--validation-metric f1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVrgU09oUJSg"
      },
      "source": [
        "## Infer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAFlnhZYhyBp"
      },
      "outputs": [],
      "source": [
        "!parlai eval_model -mf parlai/gpt-2-small-no-hla -t gutenbergbookchars:Spectrum -bs 34 \\\n",
        "  --fp16 True --dynamic-batching full \\\n",
        "  --metrics ppl,f1,accuracy,rouge,bleu --report-filename \"gpt-2-small-no-hla-report.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGXRkZEqoiY5"
      },
      "outputs": [],
      "source": [
        "# act as the pre-trained version on non-HLA.\n",
        "!parlai eval_model -mf parlai/gpt-2-small-spectrum -t gutenbergbookchars:Spectrum -bs 34 \\\n",
        "  --fp16 True --dynamic-batching full \\\n",
        "  --metrics ppl,f1,accuracy,rouge,bleu --report-filename \"gpt-2-small-hla-report.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNH841xHmvx-"
      },
      "outputs": [],
      "source": [
        "# act as the pre-trained version on non-HLA.\n",
        "!parlai eval_model -mf parlai/gpt-2-medium-no-hla \\\n",
        "  -t gutenbergbookchars:Spectrum -bs 10 --fp16 True --dynamic-batching full \\\n",
        "  --metrics ppl,f1,accuracy,rouge,bleu --report-filename \"gpt-2-medium-no-hla-report.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lubqIF-NKHw0"
      },
      "outputs": [],
      "source": [
        "!parlai eval_model -mf parlai/gpt-2-medium-spectrum \\\n",
        "  -t gutenbergbookchars:Spectrum -bs 10 \\\n",
        "  --fp16 True --dynamic-batching full --metrics ppl,f1,accuracy,rouge,bleu \\\n",
        "  --report-filename \"gpt-2-medium-hla-report.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpZDX1uysfPb"
      },
      "outputs": [],
      "source": [
        "!parlai eval_model -m hugging_face/gpt2 -t gutenbergbookchars \\\n",
        "  -bs 10 --fp16 True --dynamic-batching full --metrics ppl,f1,accuracy,rouge,bleu \\\n",
        "  --report-filename \"gpt-2-medium-report.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "golZbejLsh9j"
      },
      "outputs": [],
      "source": [
        "!parlai eval_model -m hugging_face/gpt2 --gpt2-size medium \\\n",
        "  -t gutenbergbookchars:Spectrum -bs 10 --fp16 True \\\n",
        "  --dynamic-batching full --metrics ppl,f1,accuracy,rouge,bleu"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ppd1fA1EDB4t"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kY79S1QKrE9F"
      },
      "source": [
        "# Test Zone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22HUocWPrCZ4"
      },
      "outputs": [],
      "source": [
        "!parlai eval_model --model fixed_response --task dailydialog --fixed-response \"how may i help you ?\" --metrics rouge"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CCm_jvtt3CGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!parlai eval_model -mf ./parlai/model_bi_finetuned.checkpoint -t gutenbergbookchars:S1 \\\n",
        "  --eval-candidates inline --batchsize 20 --report-filename \"S1-bi-model.json\""
      ],
      "metadata": {
        "id": "vKg7U-ey3Cds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!parlai eval_model -mf ./parlai/model_bi_finetuned.checkpoint -t gutenbergbookchars:S2 \\\n",
        "  --eval-candidates inline --batchsize 20 --report-filename \"S2-bi-model.json\""
      ],
      "metadata": {
        "id": "VfwcC4NN3L1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!parlai eval_model -mf ./parlai/model_bi_finetuned.checkpoint -t gutenbergbookchars:S3 \\\n",
        "  --eval-candidates inline --batchsize 20 --report-filename \"S3-bi-model.json\""
      ],
      "metadata": {
        "id": "D9YN57GG3NgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!parlai eval_model -mf ./parlai/model_bi_finetuned.checkpoint -t gutenbergbookchars:S4 \\\n",
        "  --eval-candidates inline --batchsize 20 --report-filename \"S4-bi-model.json\""
      ],
      "metadata": {
        "id": "vXxAIJ_v3YZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!parlai eval_model -mf ./parlai/model_bi_finetuned.checkpoint -t gutenbergbookchars:S5 \\\n",
        "  --eval-candidates inline --batchsize 20 --report-filename \"S5-bi-model.json\""
      ],
      "metadata": {
        "id": "ZDzJP8Jy3Zit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nMqMMXT16E-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!parlai eval_model -mf ./parlai/model_poly_finetuned.checkpoint -t gutenbergbookchars:S1 \\\n",
        "  --eval-candidates inline --batchsize 20 --report-filename \"S1-poly-model.json\""
      ],
      "metadata": {
        "id": "mdo_xYhC6FS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!parlai eval_model -mf ./parlai/model_poly_finetuned.checkpoint -t gutenbergbookchars:S2 \\\n",
        "  --eval-candidates inline --batchsize 20 --report-filename \"S2-poly-model.json\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUjqZFr66MUC",
        "outputId": "34365ac0-dc8c-4142-c4de-6dd920bf24cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15:03:16 | \u001b[33mOverriding opt[\"model_file\"] to ./parlai/model_poly_finetuned.checkpoint (previously: ./parlai/model_poly_finetuned)\u001b[0m\n",
            "15:03:16 | \u001b[33mOverriding opt[\"task\"] to gutenbergbookchars:S2 (previously: gutenbergbookchars)\u001b[0m\n",
            "15:03:16 | Using CUDA\n",
            "15:03:16 | loading dictionary from ./parlai/model_poly_finetuned.checkpoint.dict\n",
            "15:03:16 | num words = 54944\n",
            "15:03:20 | Total parameters: 256,131,072 (256,131,072 trainable)\n",
            "15:03:20 | Loading existing model parameters from ./parlai/model_poly_finetuned.checkpoint\n",
            "/usr/local/lib/python3.8/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "15:03:24 | Opt:\n",
            "15:03:24 |     activation: gelu\n",
            "15:03:24 |     adafactor_eps: '[1e-30, 0.001]'\n",
            "15:03:24 |     adam_eps: 1e-08\n",
            "15:03:24 |     add_p1_after_newln: False\n",
            "15:03:24 |     aggregate_micro: False\n",
            "15:03:24 |     allow_missing_init_opts: False\n",
            "15:03:24 |     area_under_curve_class: None\n",
            "15:03:24 |     area_under_curve_digits: -1\n",
            "15:03:24 |     attention_dropout: 0.1\n",
            "15:03:24 |     batchsize: 20\n",
            "15:03:24 |     betas: '[0.9, 0.999]'\n",
            "15:03:24 |     bpe_add_prefix_space: None\n",
            "15:03:24 |     bpe_debug: False\n",
            "15:03:24 |     bpe_dropout: None\n",
            "15:03:24 |     bpe_merge: None\n",
            "15:03:24 |     bpe_vocab: None\n",
            "15:03:24 |     candidates: batch\n",
            "15:03:24 |     cap_num_predictions: 100\n",
            "15:03:24 |     checkpoint_activations: False\n",
            "15:03:24 |     clearml_log: False\n",
            "15:03:24 |     clearml_project_name: ParlAI\n",
            "15:03:24 |     clearml_task_name: 'Default Task'\n",
            "15:03:24 |     codes_attention_num_heads: 4\n",
            "15:03:24 |     codes_attention_type: basic\n",
            "15:03:24 |     data_parallel: True\n",
            "15:03:24 |     datapath: /usr/local/lib/python3.8/dist-packages/data\n",
            "15:03:24 |     datatype: train\n",
            "15:03:24 |     delimiter: '\\n'\n",
            "15:03:24 |     dict_class: parlai.core.dict:DictionaryAgent\n",
            "15:03:24 |     dict_endtoken: __start__\n",
            "15:03:24 |     dict_file: ./parlai/model_poly_finetuned.checkpoint.dict\n",
            "15:03:24 |     dict_include_test: False\n",
            "15:03:24 |     dict_include_valid: False\n",
            "15:03:24 |     dict_initpath: None\n",
            "15:03:24 |     dict_language: english\n",
            "15:03:24 |     dict_loaded: True\n",
            "15:03:24 |     dict_lower: True\n",
            "15:03:24 |     dict_max_ngram_size: -1\n",
            "15:03:24 |     dict_maxexs: -1\n",
            "15:03:24 |     dict_maxtokens: -1\n",
            "15:03:24 |     dict_minfreq: 0\n",
            "15:03:24 |     dict_nulltoken: __null__\n",
            "15:03:24 |     dict_starttoken: __start__\n",
            "15:03:24 |     dict_textfields: text,labels\n",
            "15:03:24 |     dict_tokenizer: bpe\n",
            "15:03:24 |     dict_unktoken: __unk__\n",
            "15:03:24 |     display_examples: False\n",
            "15:03:24 |     download_path: None\n",
            "15:03:24 |     dropout: 0.1\n",
            "15:03:24 |     dynamic_batching: None\n",
            "15:03:24 |     embedding_projection: random\n",
            "15:03:24 |     embedding_size: 768\n",
            "15:03:24 |     embedding_type: random\n",
            "15:03:24 |     embeddings_scale: False\n",
            "15:03:24 |     encode_candidate_vecs: True\n",
            "15:03:24 |     encode_candidate_vecs_batchsize: 256\n",
            "15:03:24 |     eval_batchsize: 10\n",
            "15:03:24 |     eval_candidates: inline\n",
            "15:03:24 |     eval_dynamic_batching: None\n",
            "15:03:24 |     evaltask: None\n",
            "15:03:24 |     ffn_size: 3072\n",
            "15:03:24 |     final_extra_opt: \n",
            "15:03:24 |     fixed_candidate_vecs: reuse\n",
            "15:03:24 |     fixed_candidates_path: None\n",
            "15:03:24 |     force_fp16_tokens: True\n",
            "15:03:24 |     fp16: True\n",
            "15:03:24 |     fp16_impl: safe\n",
            "15:03:24 |     gpu: -1\n",
            "15:03:24 |     gradient_clip: 0.1\n",
            "15:03:24 |     hide_labels: False\n",
            "15:03:24 |     history_add_global_end_token: None\n",
            "15:03:24 |     history_reversed: False\n",
            "15:03:24 |     history_size: 20\n",
            "15:03:24 |     ignore_bad_candidates: False\n",
            "15:03:24 |     image_cropsize: 224\n",
            "15:03:24 |     image_mode: raw\n",
            "15:03:24 |     image_size: 256\n",
            "15:03:24 |     inference: max\n",
            "15:03:24 |     init_model: /usr/local/lib/python3.10/dist-packages/data/models/pretrained_transformers/poly_model_huge_reddit/model\n",
            "15:03:24 |     init_opt: None\n",
            "15:03:24 |     interactive_candidates: fixed\n",
            "15:03:24 |     interactive_mode: False\n",
            "15:03:24 |     invsqrt_lr_decay_gamma: -1\n",
            "15:03:24 |     is_debug: False\n",
            "15:03:24 |     label_truncate: 72\n",
            "15:03:24 |     learn_embeddings: True\n",
            "15:03:24 |     learn_positional_embeddings: True\n",
            "15:03:24 |     learningrate: 5e-05\n",
            "15:03:24 |     log_every_n_secs: 20.0\n",
            "15:03:24 |     log_every_n_steps: 50\n",
            "15:03:24 |     log_keep_fields: all\n",
            "15:03:24 |     loglevel: info\n",
            "15:03:24 |     lr_scheduler: reduceonplateau\n",
            "15:03:24 |     lr_scheduler_decay: 0.4\n",
            "15:03:24 |     lr_scheduler_patience: 0\n",
            "15:03:24 |     max_train_steps: -1\n",
            "15:03:24 |     max_train_time: 200000.0\n",
            "15:03:24 |     memory_attention: sqrt\n",
            "15:03:24 |     metrics: default\n",
            "15:03:24 |     model: transformer/polyencoder\n",
            "15:03:24 |     model_file: ./parlai/model_poly_finetuned.checkpoint\n",
            "15:03:24 |     model_parallel: False\n",
            "15:03:24 |     momentum: 0\n",
            "15:03:24 |     multitask_weights: [1]\n",
            "15:03:24 |     mutators: None\n",
            "15:03:24 |     n_decoder_layers: -1\n",
            "15:03:24 |     n_encoder_layers: -1\n",
            "15:03:24 |     n_heads: 12\n",
            "15:03:24 |     n_layers: 12\n",
            "15:03:24 |     n_positions: 1024\n",
            "15:03:24 |     n_segments: 2\n",
            "15:03:24 |     nesterov: True\n",
            "15:03:24 |     no_cuda: False\n",
            "15:03:24 |     normalize_sent_emb: False\n",
            "15:03:24 |     num_epochs: 8.0\n",
            "15:03:24 |     num_examples: -1\n",
            "15:03:24 |     num_workers: 0\n",
            "15:03:24 |     nus: [0.7]\n",
            "15:03:24 |     optimizer: adamax\n",
            "15:03:24 |     output_scaling: 0.06\n",
            "15:03:24 |     override: \"{'model_file': './parlai/model_poly_finetuned.checkpoint', 'task': 'gutenbergbookchars:S2', 'eval_candidates': 'inline', 'batchsize': 20, 'report_filename': 'S2-poly-model.json'}\"\n",
            "15:03:24 |     parlai_home: /usr/local/lib/python3.10/dist-packages\n",
            "15:03:24 |     person_tokens: False\n",
            "15:03:24 |     poly_attention_num_heads: 4\n",
            "15:03:24 |     poly_attention_type: basic\n",
            "15:03:24 |     poly_n_codes: 64\n",
            "15:03:24 |     polyencoder_type: codes\n",
            "15:03:24 |     rank_candidates: True\n",
            "15:03:24 |     rank_top_k: -1\n",
            "15:03:24 |     reduction_type: mean\n",
            "15:03:24 |     relu_dropout: 0.0\n",
            "15:03:24 |     repeat_blocking_heuristic: True\n",
            "15:03:24 |     report_filename: S2-poly-model.json\n",
            "15:03:24 |     return_cand_scores: False\n",
            "15:03:24 |     save_after_valid: True\n",
            "15:03:24 |     save_every_n_secs: -1\n",
            "15:03:24 |     save_format: conversations\n",
            "15:03:24 |     seed: None\n",
            "15:03:24 |     share_encoders: False\n",
            "15:03:24 |     share_word_embeddings: True\n",
            "15:03:24 |     short_final_eval: False\n",
            "15:03:24 |     special_tok_lst: None\n",
            "15:03:24 |     split_lines: False\n",
            "15:03:24 |     starttime: Aug30_13-52\n",
            "15:03:24 |     task: gutenbergbookchars:S2\n",
            "15:03:24 |     teacher_seed: None\n",
            "15:03:24 |     tensorboard_log: True\n",
            "15:03:24 |     tensorboard_logdir: None\n",
            "15:03:24 |     text_truncate: 360\n",
            "15:03:24 |     topk: 5\n",
            "15:03:24 |     train_predict: False\n",
            "15:03:24 |     truncate: 1024\n",
            "15:03:24 |     update_freq: 1\n",
            "15:03:24 |     use_memories: False\n",
            "15:03:24 |     use_reply: label\n",
            "15:03:24 |     validation_cutoff: 1.0\n",
            "15:03:24 |     validation_every_n_epochs: 0.5\n",
            "15:03:24 |     validation_every_n_secs: -1\n",
            "15:03:24 |     validation_every_n_steps: -1\n",
            "15:03:24 |     validation_max_exs: 8000\n",
            "15:03:24 |     validation_metric: accuracy\n",
            "15:03:24 |     validation_metric_mode: max\n",
            "15:03:24 |     validation_patience: 10\n",
            "15:03:24 |     validation_share_agent: False\n",
            "15:03:24 |     variant: xlm\n",
            "15:03:24 |     verbose: False\n",
            "15:03:24 |     wandb_entity: None\n",
            "15:03:24 |     wandb_log: False\n",
            "15:03:24 |     wandb_log_model: False\n",
            "15:03:24 |     wandb_name: None\n",
            "15:03:24 |     wandb_project: None\n",
            "15:03:24 |     warmup_rate: 0.0001\n",
            "15:03:24 |     warmup_updates: 100\n",
            "15:03:24 |     weight_decay: None\n",
            "15:03:24 |     world_logs: \n",
            "15:03:24 |     wrap_memory_encoder: False\n",
            "15:03:24 | Evaluating task gutenbergbookchars:S2 using datatype valid.\n",
            "15:03:24 | creating task(s): gutenbergbookchars:S2\n",
            "15:03:24 | loading fbdialog data: /usr/local/lib/python3.8/dist-packages/data/GutenbertBookChars/valid_155_21.txt\n",
            "/usr/local/lib/python3.8/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "15:03:24 | \u001b[33m[ Executing eval mode with provided inline set of candidates ]\u001b[0m\n",
            "15:03:26 | \u001b[1mReport for gutenbergbookchars:S2:\n",
            "    accuracy  \\\n",
            "       .3375   \n",
            "    bleu-4  \\\n",
            "     .2875   \n",
            "    clen  \\\n",
            "   71.22   \n",
            "    ctpb  \\\n",
            "    1464   \n",
            "    ctps  \\\n",
            "    4665   \n",
            "    ctrunc  \\\n",
            "         0   \n",
            "    ctrunclen  \\\n",
            "            0   \n",
            "    exps  \\\n",
            "    63.7   \n",
            "    exs  \\\n",
            "     80   \n",
            "      f1  \\\n",
            "   .3904   \n",
            "    gpu_mem  \\\n",
            "      .3052   \n",
            "    hits@1  \\\n",
            "     .3375   \n",
            "    hits@10  \\\n",
            "      .8375   \n",
            "    hits@100  \\\n",
            "           1   \n",
            "    hits@5  \\\n",
            "     .6250   \n",
            "    llen  \\\n",
            "   32.83   \n",
            "    loss  \\\n",
            "   4.765   \n",
            "          lr  \\\n",
            "   1.298e-08   \n",
            "    ltpb  \\\n",
            "   594.8   \n",
            "    ltps  \\\n",
            "    1895   \n",
            "    ltrunc  \\\n",
            "     .1625   \n",
            "    ltrunclen  \\\n",
            "        3.087   \n",
            "     mrr  \\\n",
            "   .4726   \n",
            "    precision  \\\n",
            "        .3982   \n",
            "    rank  \\\n",
            "   5.188   \n",
            "    recall  \\\n",
            "     .4115   \n",
            "    total_train_updates  \\\n",
            "                  47853   \n",
            "    tpb  \\\n",
            "   2059   \n",
            "    tps  \n",
            "   6560\u001b[0m\n",
            "15:03:26 | Finished evaluating tasks ['gutenbergbookchars:S2'] using datatype valid\n",
            "    accuracy  \\\n",
            "       .3375   \n",
            "    bleu-4  \\\n",
            "     .2875   \n",
            "    clen  \\\n",
            "   71.22   \n",
            "    ctpb  \\\n",
            "    1464   \n",
            "    ctps  \\\n",
            "    4665   \n",
            "    ctrunc  \\\n",
            "         0   \n",
            "    ctrunclen  \\\n",
            "            0   \n",
            "    exps  \\\n",
            "    63.7   \n",
            "    exs  \\\n",
            "     80   \n",
            "      f1  \\\n",
            "   .3904   \n",
            "    gpu_mem  \\\n",
            "      .3052   \n",
            "    hits@1  \\\n",
            "     .3375   \n",
            "    hits@10  \\\n",
            "      .8375   \n",
            "    hits@100  \\\n",
            "           1   \n",
            "    hits@5  \\\n",
            "     .6250   \n",
            "    llen  \\\n",
            "   32.83   \n",
            "    loss  \\\n",
            "   4.765   \n",
            "          lr  \\\n",
            "   1.298e-08   \n",
            "    ltpb  \\\n",
            "   594.8   \n",
            "    ltps  \\\n",
            "    1895   \n",
            "    ltrunc  \\\n",
            "     .1625   \n",
            "    ltrunclen  \\\n",
            "        3.087   \n",
            "     mrr  \\\n",
            "   .4726   \n",
            "    precision  \\\n",
            "        .3982   \n",
            "    rank  \\\n",
            "   5.188   \n",
            "    recall  \\\n",
            "     .4115   \n",
            "    total_train_updates  \\\n",
            "                  47853   \n",
            "    tpb  \\\n",
            "   2059   \n",
            "    tps  \n",
            "   6560\n",
            "15:03:26 | Saving model report to S2-poly-model.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!parlai eval_model -mf ./parlai/model_poly_finetuned.checkpoint -t gutenbergbookchars:S3 \\\n",
        "  --eval-candidates inline --batchsize 20 --report-filename \"S3-poly-model.json\""
      ],
      "metadata": {
        "id": "44Qzxeek6bJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!parlai eval_model -mf ./parlai/model_poly_finetuned.checkpoint -t gutenbergbookchars:S4 \\\n",
        "  --eval-candidates inline --batchsize 20 --report-filename \"S4-poly-model.json\""
      ],
      "metadata": {
        "id": "ohRUd6E36dIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!parlai eval_model -mf ./parlai/model_poly_finetuned.checkpoint -t gutenbergbookchars:S5 \\\n",
        "  --eval-candidates inline --batchsize 20 --report-filename \"S5-poly-model.json\""
      ],
      "metadata": {
        "id": "EG-glqYP6eyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!parlai eval_model -mf parlai/gpt-2-small-spectrum \\\n",
        "  -t gutenbergbookchars:S1 -bs 10 \\\n",
        "  --fp16 True --dynamic-batching full --metrics ppl,f1,accuracy,rouge,bleu \\\n",
        "  --report-filename \"s1-gpt2-small.json\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9AQ3W4S7ioN",
        "outputId": "41f01a52-36f0-4bb5-fd7d-b78fcef83cd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15:15:44 | \u001b[33mWARNING: this model is in beta and the API is subject to change.\u001b[0m\n",
            "15:15:44 | \u001b[33mOverriding opt[\"task\"] to gutenbergbookchars:S1 (previously: gutenbergbookchars:Spectrum)\u001b[0m\n",
            "15:15:44 | \u001b[33mOverriding opt[\"batchsize\"] to 10 (previously: 8)\u001b[0m\n",
            "15:15:44 | \u001b[33mOverriding opt[\"metrics\"] to ppl,f1,accuracy,rouge,bleu (previously: default)\u001b[0m\n",
            "15:15:44 | Using CUDA\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50260. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "15:15:48 | Total parameters: 124,442,112 (124,442,112 trainable)\n",
            "15:15:48 | Loading existing model params from parlai/gpt-2-small-spectrum\n",
            "15:15:48 | Opt:\n",
            "15:15:48 |     adafactor_eps: '[1e-30, 0.001]'\n",
            "15:15:48 |     adam_eps: 1e-08\n",
            "15:15:48 |     add_p1_after_newln: False\n",
            "15:15:48 |     add_special_tokens: True\n",
            "15:15:48 |     add_start_token: True\n",
            "15:15:48 |     aggregate_micro: False\n",
            "15:15:48 |     allow_missing_init_opts: False\n",
            "15:15:48 |     area_under_curve_class: None\n",
            "15:15:48 |     area_under_curve_digits: -1\n",
            "15:15:48 |     batchsize: 10\n",
            "15:15:48 |     beam_block_full_context: True\n",
            "15:15:48 |     beam_block_list_filename: None\n",
            "15:15:48 |     beam_block_ngram: -1\n",
            "15:15:48 |     beam_context_block_ngram: -1\n",
            "15:15:48 |     beam_delay: 30\n",
            "15:15:48 |     beam_length_penalty: 0.65\n",
            "15:15:48 |     beam_min_length: 1\n",
            "15:15:48 |     beam_size: 1\n",
            "15:15:48 |     betas: '[0.9, 0.999]'\n",
            "15:15:48 |     bpe_add_prefix_space: None\n",
            "15:15:48 |     bpe_debug: False\n",
            "15:15:48 |     bpe_dropout: None\n",
            "15:15:48 |     bpe_merge: None\n",
            "15:15:48 |     bpe_vocab: None\n",
            "15:15:48 |     clearml_log: False\n",
            "15:15:48 |     clearml_project_name: ParlAI\n",
            "15:15:48 |     clearml_task_name: 'Default Task'\n",
            "15:15:48 |     compute_tokenized_bleu: False\n",
            "15:15:48 |     datapath: /usr/local/lib/python3.8/dist-packages/data\n",
            "15:15:48 |     datatype: train\n",
            "15:15:48 |     delimiter: '\\n'\n",
            "15:15:48 |     dict_class: parlai.agents.hugging_face.dict:Gpt2DictionaryAgent\n",
            "15:15:48 |     dict_endtoken: __end__\n",
            "15:15:48 |     dict_file: parlai/gpt-2-small-spectrum.dict\n",
            "15:15:48 |     dict_include_test: False\n",
            "15:15:48 |     dict_include_valid: False\n",
            "15:15:48 |     dict_initpath: None\n",
            "15:15:48 |     dict_language: english\n",
            "15:15:48 |     dict_lower: False\n",
            "15:15:48 |     dict_max_ngram_size: -1\n",
            "15:15:48 |     dict_maxexs: 0\n",
            "15:15:48 |     dict_maxtokens: -1\n",
            "15:15:48 |     dict_minfreq: 0\n",
            "15:15:48 |     dict_nulltoken: __null__\n",
            "15:15:48 |     dict_starttoken: __start__\n",
            "15:15:48 |     dict_textfields: text,labels\n",
            "15:15:48 |     dict_tokenizer: re\n",
            "15:15:48 |     dict_unktoken: __unk__\n",
            "15:15:48 |     display_examples: False\n",
            "15:15:48 |     download_path: None\n",
            "15:15:48 |     dynamic_batching: full\n",
            "15:15:48 |     embedding_projection: random\n",
            "15:15:48 |     embedding_type: random\n",
            "15:15:48 |     eval_batchsize: None\n",
            "15:15:48 |     eval_dynamic_batching: None\n",
            "15:15:48 |     evaltask: None\n",
            "15:15:48 |     final_extra_opt: \n",
            "15:15:48 |     force_fp16_tokens: True\n",
            "15:15:48 |     fp16: True\n",
            "15:15:48 |     fp16_impl: safe\n",
            "15:15:48 |     gpt2_size: small\n",
            "15:15:48 |     gpu: -1\n",
            "15:15:48 |     gpu_beam_blocking: False\n",
            "15:15:48 |     gradient_clip: 0.1\n",
            "15:15:48 |     hide_labels: False\n",
            "15:15:48 |     history_add_global_end_token: None\n",
            "15:15:48 |     history_reversed: False\n",
            "15:15:48 |     history_size: -1\n",
            "15:15:48 |     image_cropsize: 224\n",
            "15:15:48 |     image_mode: raw\n",
            "15:15:48 |     image_size: 256\n",
            "15:15:48 |     inference: greedy\n",
            "15:15:48 |     init_model: parlai/gpt-2-small-spectrum.checkpoint\n",
            "15:15:48 |     init_opt: None\n",
            "15:15:48 |     interactive_mode: False\n",
            "15:15:48 |     invsqrt_lr_decay_gamma: -1\n",
            "15:15:48 |     is_debug: False\n",
            "15:15:48 |     label_truncate: 256\n",
            "15:15:48 |     lambda_decay: 0.9\n",
            "15:15:48 |     learningrate: 1\n",
            "15:15:48 |     log_every_n_secs: -1\n",
            "15:15:48 |     log_every_n_steps: 50\n",
            "15:15:48 |     log_keep_fields: all\n",
            "15:15:48 |     loglevel: info\n",
            "15:15:48 |     lr_scheduler: reduceonplateau\n",
            "15:15:48 |     lr_scheduler_decay: 0.5\n",
            "15:15:48 |     lr_scheduler_patience: 3\n",
            "15:15:48 |     max_train_steps: -1\n",
            "15:15:48 |     max_train_time: -1\n",
            "15:15:48 |     metrics: ppl,f1,accuracy,rouge,bleu\n",
            "15:15:48 |     model: hugging_face/gpt2\n",
            "15:15:48 |     model_file: parlai/gpt-2-small-spectrum\n",
            "15:15:48 |     model_name: None\n",
            "15:15:48 |     momentum: 0\n",
            "15:15:48 |     multitask_weights: [1]\n",
            "15:15:48 |     mutators: None\n",
            "15:15:48 |     nesterov: True\n",
            "15:15:48 |     no_cuda: False\n",
            "15:15:48 |     num_epochs: 6.0\n",
            "15:15:48 |     num_examples: -1\n",
            "15:15:48 |     num_workers: 0\n",
            "15:15:48 |     nus: [0.7]\n",
            "15:15:48 |     omega_bound: 0.3\n",
            "15:15:48 |     optimizer: sgd\n",
            "15:15:48 |     override: \"{'model_file': 'parlai/gpt-2-small-spectrum', 'task': 'gutenbergbookchars:S1', 'batchsize': 10, 'fp16': True, 'dynamic_batching': 'full', 'metrics': 'ppl,f1,accuracy,rouge,bleu', 'report_filename': 's1-gpt2-small.json'}\"\n",
            "15:15:48 |     p_reset: True\n",
            "15:15:48 |     parlai_home: /usr/local/lib/python3.8/dist-packages\n",
            "15:15:48 |     person_tokens: False\n",
            "15:15:48 |     rank_candidates: False\n",
            "15:15:48 |     report_filename: s1-gpt2-small.json\n",
            "15:15:48 |     save_after_valid: True\n",
            "15:15:48 |     save_every_n_secs: -1\n",
            "15:15:48 |     save_format: conversations\n",
            "15:15:48 |     seed: None\n",
            "15:15:48 |     short_final_eval: False\n",
            "15:15:48 |     skip_generation: False\n",
            "15:15:48 |     special_tok_lst: None\n",
            "15:15:48 |     split_lines: False\n",
            "15:15:48 |     starttime: Aug14_17-53\n",
            "15:15:48 |     task: gutenbergbookchars:S1\n",
            "15:15:48 |     teacher_seed: None\n",
            "15:15:48 |     temperature: 1.0\n",
            "15:15:48 |     tensorboard_log: True\n",
            "15:15:48 |     tensorboard_logdir: None\n",
            "15:15:48 |     text_truncate: 360\n",
            "15:15:48 |     topk: 10\n",
            "15:15:48 |     topp: 0.9\n",
            "15:15:48 |     truncate: -1\n",
            "15:15:48 |     update_freq: 1\n",
            "15:15:48 |     use_reply: label\n",
            "15:15:48 |     validation_cutoff: 1.0\n",
            "15:15:48 |     validation_every_n_epochs: 0.5\n",
            "15:15:48 |     validation_every_n_secs: -1\n",
            "15:15:48 |     validation_every_n_steps: -1\n",
            "15:15:48 |     validation_max_exs: -1\n",
            "15:15:48 |     validation_metric: f1\n",
            "15:15:48 |     validation_metric_mode: None\n",
            "15:15:48 |     validation_patience: 10\n",
            "15:15:48 |     validation_share_agent: False\n",
            "15:15:48 |     verbose: False\n",
            "15:15:48 |     verbose_topk: -1\n",
            "15:15:48 |     wandb_entity: None\n",
            "15:15:48 |     wandb_log: False\n",
            "15:15:48 |     wandb_log_model: False\n",
            "15:15:48 |     wandb_name: None\n",
            "15:15:48 |     wandb_project: None\n",
            "15:15:48 |     warmup_rate: 0.0001\n",
            "15:15:48 |     warmup_updates: -1\n",
            "15:15:48 |     weight_decay: None\n",
            "15:15:48 |     world_logs: \n",
            "15:15:48 | Evaluating task gutenbergbookchars:S1 using datatype valid.\n",
            "15:15:48 | creating task(s): gutenbergbookchars:S1\n",
            "15:15:48 | loading fbdialog data: /usr/local/lib/python3.8/dist-packages/data/GutenbertBookChars/valid_139_1.txt\n",
            "15:15:51 | \u001b[1mReport for gutenbergbookchars:S1:\n",
            "    accuracy  \\\n",
            "           0   \n",
            "    bleu-1  \\\n",
            "    .05804   \n",
            "    bleu-2  \\\n",
            "    .01362   \n",
            "    bleu-3  \\\n",
            "     .0050   \n",
            "      bleu-4  \\\n",
            "   4.306e-06   \n",
            "    clen  \\\n",
            "   94.88   \n",
            "    ctpb  \\\n",
            "    3036   \n",
            "    ctps  \\\n",
            "    2382   \n",
            "    ctrunc  \\\n",
            "         0   \n",
            "    ctrunclen  \\\n",
            "            0   \n",
            "    exps  \\\n",
            "    25.1   \n",
            "    exs  \\\n",
            "     32   \n",
            "       f1  \\\n",
            "   .09276   \n",
            "    gen_n_toks  \\\n",
            "         19.09   \n",
            "    gpu_mem  \\\n",
            "      .1220   \n",
            "    llen  \\\n",
            "   26.28   \n",
            "    loss  \\\n",
            "   3.764   \n",
            "      lr  \\\n",
            "   .5000   \n",
            "    ltpb  \\\n",
            "     841   \n",
            "    ltps  \\\n",
            "   659.9   \n",
            "    ltrunc  \\\n",
            "         0   \n",
            "    ltrunclen  \\\n",
            "            0   \n",
            "     ppl  \\\n",
            "   43.14   \n",
            "    precision  \\\n",
            "        .1290   \n",
            "    recall  \\\n",
            "     .0882   \n",
            "    rouge_1  \\\n",
            "     .09375   \n",
            "    rouge_2  \\\n",
            "     .01167   \n",
            "    rouge_L  \\\n",
            "     .08762   \n",
            "    token_acc  \\\n",
            "        .3187   \n",
            "    token_em  \\\n",
            "           0   \n",
            "    total_train_updates  \\\n",
            "                  20132   \n",
            "    tpb  \\\n",
            "   3877   \n",
            "    tps  \n",
            "   3042\u001b[0m\n",
            "15:15:51 | Finished evaluating tasks ['gutenbergbookchars:S1'] using datatype valid\n",
            "    accuracy  \\\n",
            "           0   \n",
            "    bleu-1  \\\n",
            "    .05804   \n",
            "    bleu-2  \\\n",
            "    .01362   \n",
            "    bleu-3  \\\n",
            "     .0050   \n",
            "      bleu-4  \\\n",
            "   4.306e-06   \n",
            "    clen  \\\n",
            "   94.88   \n",
            "    ctpb  \\\n",
            "    3036   \n",
            "    ctps  \\\n",
            "    2382   \n",
            "    ctrunc  \\\n",
            "         0   \n",
            "    ctrunclen  \\\n",
            "            0   \n",
            "    exps  \\\n",
            "    25.1   \n",
            "    exs  \\\n",
            "     32   \n",
            "       f1  \\\n",
            "   .09276   \n",
            "    gen_n_toks  \\\n",
            "         19.09   \n",
            "    gpu_mem  \\\n",
            "      .1220   \n",
            "    llen  \\\n",
            "   26.28   \n",
            "    loss  \\\n",
            "   3.764   \n",
            "      lr  \\\n",
            "   .5000   \n",
            "    ltpb  \\\n",
            "     841   \n",
            "    ltps  \\\n",
            "   659.9   \n",
            "    ltrunc  \\\n",
            "         0   \n",
            "    ltrunclen  \\\n",
            "            0   \n",
            "     ppl  \\\n",
            "   43.14   \n",
            "    precision  \\\n",
            "        .1290   \n",
            "    recall  \\\n",
            "     .0882   \n",
            "    rouge_1  \\\n",
            "     .09375   \n",
            "    rouge_2  \\\n",
            "     .01167   \n",
            "    rouge_L  \\\n",
            "     .08762   \n",
            "    token_acc  \\\n",
            "        .3187   \n",
            "    token_em  \\\n",
            "           0   \n",
            "    total_train_updates  \\\n",
            "                  20132   \n",
            "    tpb  \\\n",
            "   3877   \n",
            "    tps  \n",
            "   3042\n",
            "15:15:51 | Saving model report to s1-gpt2-small.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!parlai eval_model -mf parlai/gpt-2-small-spectrum \\\n",
        "  -t gutenbergbookchars:S2 -bs 10 \\\n",
        "  --fp16 True --dynamic-batching full --metrics ppl,f1,accuracy,rouge,bleu \\\n",
        "  --report-filename \"s2-gpt2-small.json\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1ETfPsE7r8y",
        "outputId": "4079b543-8446-4543-c50e-75ff49d5839b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15:15:32 | \u001b[33mWARNING: this model is in beta and the API is subject to change.\u001b[0m\n",
            "15:15:32 | \u001b[33mOverriding opt[\"task\"] to gutenbergbookchars:S2 (previously: gutenbergbookchars:Spectrum)\u001b[0m\n",
            "15:15:32 | \u001b[33mOverriding opt[\"batchsize\"] to 10 (previously: 8)\u001b[0m\n",
            "15:15:32 | \u001b[33mOverriding opt[\"metrics\"] to ppl,f1,accuracy,rouge,bleu (previously: default)\u001b[0m\n",
            "15:15:32 | Using CUDA\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50260. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "15:15:36 | Total parameters: 124,442,112 (124,442,112 trainable)\n",
            "15:15:36 | Loading existing model params from parlai/gpt-2-small-spectrum\n",
            "15:15:36 | Opt:\n",
            "15:15:36 |     adafactor_eps: '[1e-30, 0.001]'\n",
            "15:15:36 |     adam_eps: 1e-08\n",
            "15:15:36 |     add_p1_after_newln: False\n",
            "15:15:36 |     add_special_tokens: True\n",
            "15:15:36 |     add_start_token: True\n",
            "15:15:36 |     aggregate_micro: False\n",
            "15:15:36 |     allow_missing_init_opts: False\n",
            "15:15:36 |     area_under_curve_class: None\n",
            "15:15:36 |     area_under_curve_digits: -1\n",
            "15:15:36 |     batchsize: 10\n",
            "15:15:36 |     beam_block_full_context: True\n",
            "15:15:36 |     beam_block_list_filename: None\n",
            "15:15:36 |     beam_block_ngram: -1\n",
            "15:15:36 |     beam_context_block_ngram: -1\n",
            "15:15:36 |     beam_delay: 30\n",
            "15:15:36 |     beam_length_penalty: 0.65\n",
            "15:15:36 |     beam_min_length: 1\n",
            "15:15:36 |     beam_size: 1\n",
            "15:15:36 |     betas: '[0.9, 0.999]'\n",
            "15:15:36 |     bpe_add_prefix_space: None\n",
            "15:15:36 |     bpe_debug: False\n",
            "15:15:36 |     bpe_dropout: None\n",
            "15:15:36 |     bpe_merge: None\n",
            "15:15:36 |     bpe_vocab: None\n",
            "15:15:36 |     clearml_log: False\n",
            "15:15:36 |     clearml_project_name: ParlAI\n",
            "15:15:36 |     clearml_task_name: 'Default Task'\n",
            "15:15:36 |     compute_tokenized_bleu: False\n",
            "15:15:36 |     datapath: /usr/local/lib/python3.8/dist-packages/data\n",
            "15:15:36 |     datatype: train\n",
            "15:15:36 |     delimiter: '\\n'\n",
            "15:15:36 |     dict_class: parlai.agents.hugging_face.dict:Gpt2DictionaryAgent\n",
            "15:15:36 |     dict_endtoken: __end__\n",
            "15:15:36 |     dict_file: parlai/gpt-2-small-spectrum.dict\n",
            "15:15:36 |     dict_include_test: False\n",
            "15:15:36 |     dict_include_valid: False\n",
            "15:15:36 |     dict_initpath: None\n",
            "15:15:36 |     dict_language: english\n",
            "15:15:36 |     dict_lower: False\n",
            "15:15:36 |     dict_max_ngram_size: -1\n",
            "15:15:36 |     dict_maxexs: 0\n",
            "15:15:36 |     dict_maxtokens: -1\n",
            "15:15:36 |     dict_minfreq: 0\n",
            "15:15:36 |     dict_nulltoken: __null__\n",
            "15:15:36 |     dict_starttoken: __start__\n",
            "15:15:36 |     dict_textfields: text,labels\n",
            "15:15:36 |     dict_tokenizer: re\n",
            "15:15:36 |     dict_unktoken: __unk__\n",
            "15:15:36 |     display_examples: False\n",
            "15:15:36 |     download_path: None\n",
            "15:15:36 |     dynamic_batching: full\n",
            "15:15:36 |     embedding_projection: random\n",
            "15:15:36 |     embedding_type: random\n",
            "15:15:36 |     eval_batchsize: None\n",
            "15:15:36 |     eval_dynamic_batching: None\n",
            "15:15:36 |     evaltask: None\n",
            "15:15:36 |     final_extra_opt: \n",
            "15:15:36 |     force_fp16_tokens: True\n",
            "15:15:36 |     fp16: True\n",
            "15:15:36 |     fp16_impl: safe\n",
            "15:15:36 |     gpt2_size: small\n",
            "15:15:36 |     gpu: -1\n",
            "15:15:36 |     gpu_beam_blocking: False\n",
            "15:15:36 |     gradient_clip: 0.1\n",
            "15:15:36 |     hide_labels: False\n",
            "15:15:36 |     history_add_global_end_token: None\n",
            "15:15:36 |     history_reversed: False\n",
            "15:15:36 |     history_size: -1\n",
            "15:15:36 |     image_cropsize: 224\n",
            "15:15:36 |     image_mode: raw\n",
            "15:15:36 |     image_size: 256\n",
            "15:15:36 |     inference: greedy\n",
            "15:15:36 |     init_model: parlai/gpt-2-small-spectrum.checkpoint\n",
            "15:15:36 |     init_opt: None\n",
            "15:15:36 |     interactive_mode: False\n",
            "15:15:36 |     invsqrt_lr_decay_gamma: -1\n",
            "15:15:36 |     is_debug: False\n",
            "15:15:36 |     label_truncate: 256\n",
            "15:15:36 |     lambda_decay: 0.9\n",
            "15:15:36 |     learningrate: 1\n",
            "15:15:36 |     log_every_n_secs: -1\n",
            "15:15:36 |     log_every_n_steps: 50\n",
            "15:15:36 |     log_keep_fields: all\n",
            "15:15:36 |     loglevel: info\n",
            "15:15:36 |     lr_scheduler: reduceonplateau\n",
            "15:15:36 |     lr_scheduler_decay: 0.5\n",
            "15:15:36 |     lr_scheduler_patience: 3\n",
            "15:15:36 |     max_train_steps: -1\n",
            "15:15:36 |     max_train_time: -1\n",
            "15:15:36 |     metrics: ppl,f1,accuracy,rouge,bleu\n",
            "15:15:36 |     model: hugging_face/gpt2\n",
            "15:15:36 |     model_file: parlai/gpt-2-small-spectrum\n",
            "15:15:36 |     model_name: None\n",
            "15:15:36 |     momentum: 0\n",
            "15:15:36 |     multitask_weights: [1]\n",
            "15:15:36 |     mutators: None\n",
            "15:15:36 |     nesterov: True\n",
            "15:15:36 |     no_cuda: False\n",
            "15:15:36 |     num_epochs: 6.0\n",
            "15:15:36 |     num_examples: -1\n",
            "15:15:36 |     num_workers: 0\n",
            "15:15:36 |     nus: [0.7]\n",
            "15:15:36 |     omega_bound: 0.3\n",
            "15:15:36 |     optimizer: sgd\n",
            "15:15:36 |     override: \"{'model_file': 'parlai/gpt-2-small-spectrum', 'task': 'gutenbergbookchars:S2', 'batchsize': 10, 'fp16': True, 'dynamic_batching': 'full', 'metrics': 'ppl,f1,accuracy,rouge,bleu', 'report_filename': 's2-gpt2-small.json'}\"\n",
            "15:15:36 |     p_reset: True\n",
            "15:15:36 |     parlai_home: /usr/local/lib/python3.8/dist-packages\n",
            "15:15:36 |     person_tokens: False\n",
            "15:15:36 |     rank_candidates: False\n",
            "15:15:36 |     report_filename: s2-gpt2-small.json\n",
            "15:15:36 |     save_after_valid: True\n",
            "15:15:36 |     save_every_n_secs: -1\n",
            "15:15:36 |     save_format: conversations\n",
            "15:15:36 |     seed: None\n",
            "15:15:36 |     short_final_eval: False\n",
            "15:15:36 |     skip_generation: False\n",
            "15:15:36 |     special_tok_lst: None\n",
            "15:15:36 |     split_lines: False\n",
            "15:15:36 |     starttime: Aug14_17-53\n",
            "15:15:36 |     task: gutenbergbookchars:S2\n",
            "15:15:36 |     teacher_seed: None\n",
            "15:15:36 |     temperature: 1.0\n",
            "15:15:36 |     tensorboard_log: True\n",
            "15:15:36 |     tensorboard_logdir: None\n",
            "15:15:36 |     text_truncate: 360\n",
            "15:15:36 |     topk: 10\n",
            "15:15:36 |     topp: 0.9\n",
            "15:15:36 |     truncate: -1\n",
            "15:15:36 |     update_freq: 1\n",
            "15:15:36 |     use_reply: label\n",
            "15:15:36 |     validation_cutoff: 1.0\n",
            "15:15:36 |     validation_every_n_epochs: 0.5\n",
            "15:15:36 |     validation_every_n_secs: -1\n",
            "15:15:36 |     validation_every_n_steps: -1\n",
            "15:15:36 |     validation_max_exs: -1\n",
            "15:15:36 |     validation_metric: f1\n",
            "15:15:36 |     validation_metric_mode: None\n",
            "15:15:36 |     validation_patience: 10\n",
            "15:15:36 |     validation_share_agent: False\n",
            "15:15:36 |     verbose: False\n",
            "15:15:36 |     verbose_topk: -1\n",
            "15:15:36 |     wandb_entity: None\n",
            "15:15:36 |     wandb_log: False\n",
            "15:15:36 |     wandb_log_model: False\n",
            "15:15:36 |     wandb_name: None\n",
            "15:15:36 |     wandb_project: None\n",
            "15:15:36 |     warmup_rate: 0.0001\n",
            "15:15:36 |     warmup_updates: -1\n",
            "15:15:36 |     weight_decay: None\n",
            "15:15:36 |     world_logs: \n",
            "15:15:36 | Evaluating task gutenbergbookchars:S2 using datatype valid.\n",
            "15:15:36 | creating task(s): gutenbergbookchars:S2\n",
            "15:15:36 | loading fbdialog data: /usr/local/lib/python3.8/dist-packages/data/GutenbertBookChars/valid_155_21.txt\n",
            "15:15:40 | \u001b[1mReport for gutenbergbookchars:S2:\n",
            "    accuracy  \\\n",
            "           0   \n",
            "    bleu-1  \\\n",
            "    .05347   \n",
            "    bleu-2  \\\n",
            "    .01205   \n",
            "    bleu-3  \\\n",
            "   .002954   \n",
            "     bleu-4  \\\n",
            "   .0001832   \n",
            "    clen  \\\n",
            "   79.28   \n",
            "    ctpb  \\\n",
            "    3171   \n",
            "    ctps  \\\n",
            "    2656   \n",
            "    ctrunc  \\\n",
            "         0   \n",
            "    ctrunclen  \\\n",
            "            0   \n",
            "    exps  \\\n",
            "    33.5   \n",
            "    exs  \\\n",
            "     80   \n",
            "       f1  \\\n",
            "   .09766   \n",
            "    gen_n_toks  \\\n",
            "         17.86   \n",
            "    gpu_mem  \\\n",
            "      .1697   \n",
            "    llen  \\\n",
            "   32.11   \n",
            "    loss  \\\n",
            "   3.788   \n",
            "      lr  \\\n",
            "   .5000   \n",
            "    ltpb  \\\n",
            "    1284   \n",
            "    ltps  \\\n",
            "    1076   \n",
            "    ltrunc  \\\n",
            "         0   \n",
            "    ltrunclen  \\\n",
            "            0   \n",
            "     ppl  \\\n",
            "   44.17   \n",
            "    precision  \\\n",
            "        .1582   \n",
            "    recall  \\\n",
            "     .1040   \n",
            "    rouge_1  \\\n",
            "      .1095   \n",
            "    rouge_2  \\\n",
            "     .02507   \n",
            "    rouge_L  \\\n",
            "      .1024   \n",
            "    token_acc  \\\n",
            "        .3204   \n",
            "    token_em  \\\n",
            "           0   \n",
            "    total_train_updates  \\\n",
            "                  20132   \n",
            "    tpb  \\\n",
            "   4456   \n",
            "    tps  \n",
            "   3732\u001b[0m\n",
            "15:15:40 | Finished evaluating tasks ['gutenbergbookchars:S2'] using datatype valid\n",
            "    accuracy  \\\n",
            "           0   \n",
            "    bleu-1  \\\n",
            "    .05347   \n",
            "    bleu-2  \\\n",
            "    .01205   \n",
            "    bleu-3  \\\n",
            "   .002954   \n",
            "     bleu-4  \\\n",
            "   .0001832   \n",
            "    clen  \\\n",
            "   79.28   \n",
            "    ctpb  \\\n",
            "    3171   \n",
            "    ctps  \\\n",
            "    2656   \n",
            "    ctrunc  \\\n",
            "         0   \n",
            "    ctrunclen  \\\n",
            "            0   \n",
            "    exps  \\\n",
            "    33.5   \n",
            "    exs  \\\n",
            "     80   \n",
            "       f1  \\\n",
            "   .09766   \n",
            "    gen_n_toks  \\\n",
            "         17.86   \n",
            "    gpu_mem  \\\n",
            "      .1697   \n",
            "    llen  \\\n",
            "   32.11   \n",
            "    loss  \\\n",
            "   3.788   \n",
            "      lr  \\\n",
            "   .5000   \n",
            "    ltpb  \\\n",
            "    1284   \n",
            "    ltps  \\\n",
            "    1076   \n",
            "    ltrunc  \\\n",
            "         0   \n",
            "    ltrunclen  \\\n",
            "            0   \n",
            "     ppl  \\\n",
            "   44.17   \n",
            "    precision  \\\n",
            "        .1582   \n",
            "    recall  \\\n",
            "     .1040   \n",
            "    rouge_1  \\\n",
            "      .1095   \n",
            "    rouge_2  \\\n",
            "     .02507   \n",
            "    rouge_L  \\\n",
            "      .1024   \n",
            "    token_acc  \\\n",
            "        .3204   \n",
            "    token_em  \\\n",
            "           0   \n",
            "    total_train_updates  \\\n",
            "                  20132   \n",
            "    tpb  \\\n",
            "   4456   \n",
            "    tps  \n",
            "   3732\n",
            "15:15:40 | Saving model report to s2-gpt2-small.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!parlai eval_model -mf parlai/gpt-2-small-spectrum \\\n",
        "  -t gutenbergbookchars:S3 -bs 10 \\\n",
        "  --fp16 True --dynamic-batching full --metrics ppl,f1,accuracy,rouge,bleu \\\n",
        "  --report-filename \"s3-gpt2-small.json\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWUTKHBN8Azx",
        "outputId": "559a5c11-3731-4252-aff3-fd8d715951e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15:15:21 | \u001b[33mWARNING: this model is in beta and the API is subject to change.\u001b[0m\n",
            "15:15:21 | \u001b[33mOverriding opt[\"task\"] to gutenbergbookchars:S3 (previously: gutenbergbookchars:Spectrum)\u001b[0m\n",
            "15:15:21 | \u001b[33mOverriding opt[\"batchsize\"] to 10 (previously: 8)\u001b[0m\n",
            "15:15:21 | \u001b[33mOverriding opt[\"metrics\"] to ppl,f1,accuracy,rouge,bleu (previously: default)\u001b[0m\n",
            "15:15:21 | Using CUDA\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50260. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "15:15:25 | Total parameters: 124,442,112 (124,442,112 trainable)\n",
            "15:15:25 | Loading existing model params from parlai/gpt-2-small-spectrum\n",
            "15:15:25 | Opt:\n",
            "15:15:25 |     adafactor_eps: '[1e-30, 0.001]'\n",
            "15:15:25 |     adam_eps: 1e-08\n",
            "15:15:25 |     add_p1_after_newln: False\n",
            "15:15:25 |     add_special_tokens: True\n",
            "15:15:25 |     add_start_token: True\n",
            "15:15:25 |     aggregate_micro: False\n",
            "15:15:25 |     allow_missing_init_opts: False\n",
            "15:15:25 |     area_under_curve_class: None\n",
            "15:15:25 |     area_under_curve_digits: -1\n",
            "15:15:25 |     batchsize: 10\n",
            "15:15:25 |     beam_block_full_context: True\n",
            "15:15:25 |     beam_block_list_filename: None\n",
            "15:15:25 |     beam_block_ngram: -1\n",
            "15:15:25 |     beam_context_block_ngram: -1\n",
            "15:15:25 |     beam_delay: 30\n",
            "15:15:25 |     beam_length_penalty: 0.65\n",
            "15:15:25 |     beam_min_length: 1\n",
            "15:15:25 |     beam_size: 1\n",
            "15:15:25 |     betas: '[0.9, 0.999]'\n",
            "15:15:25 |     bpe_add_prefix_space: None\n",
            "15:15:25 |     bpe_debug: False\n",
            "15:15:25 |     bpe_dropout: None\n",
            "15:15:25 |     bpe_merge: None\n",
            "15:15:25 |     bpe_vocab: None\n",
            "15:15:25 |     clearml_log: False\n",
            "15:15:25 |     clearml_project_name: ParlAI\n",
            "15:15:25 |     clearml_task_name: 'Default Task'\n",
            "15:15:25 |     compute_tokenized_bleu: False\n",
            "15:15:25 |     datapath: /usr/local/lib/python3.8/dist-packages/data\n",
            "15:15:25 |     datatype: train\n",
            "15:15:25 |     delimiter: '\\n'\n",
            "15:15:25 |     dict_class: parlai.agents.hugging_face.dict:Gpt2DictionaryAgent\n",
            "15:15:25 |     dict_endtoken: __end__\n",
            "15:15:25 |     dict_file: parlai/gpt-2-small-spectrum.dict\n",
            "15:15:25 |     dict_include_test: False\n",
            "15:15:25 |     dict_include_valid: False\n",
            "15:15:25 |     dict_initpath: None\n",
            "15:15:25 |     dict_language: english\n",
            "15:15:25 |     dict_lower: False\n",
            "15:15:25 |     dict_max_ngram_size: -1\n",
            "15:15:25 |     dict_maxexs: 0\n",
            "15:15:25 |     dict_maxtokens: -1\n",
            "15:15:25 |     dict_minfreq: 0\n",
            "15:15:25 |     dict_nulltoken: __null__\n",
            "15:15:25 |     dict_starttoken: __start__\n",
            "15:15:25 |     dict_textfields: text,labels\n",
            "15:15:25 |     dict_tokenizer: re\n",
            "15:15:25 |     dict_unktoken: __unk__\n",
            "15:15:25 |     display_examples: False\n",
            "15:15:25 |     download_path: None\n",
            "15:15:25 |     dynamic_batching: full\n",
            "15:15:25 |     embedding_projection: random\n",
            "15:15:25 |     embedding_type: random\n",
            "15:15:25 |     eval_batchsize: None\n",
            "15:15:25 |     eval_dynamic_batching: None\n",
            "15:15:25 |     evaltask: None\n",
            "15:15:25 |     final_extra_opt: \n",
            "15:15:25 |     force_fp16_tokens: True\n",
            "15:15:25 |     fp16: True\n",
            "15:15:25 |     fp16_impl: safe\n",
            "15:15:25 |     gpt2_size: small\n",
            "15:15:25 |     gpu: -1\n",
            "15:15:25 |     gpu_beam_blocking: False\n",
            "15:15:25 |     gradient_clip: 0.1\n",
            "15:15:25 |     hide_labels: False\n",
            "15:15:25 |     history_add_global_end_token: None\n",
            "15:15:25 |     history_reversed: False\n",
            "15:15:25 |     history_size: -1\n",
            "15:15:25 |     image_cropsize: 224\n",
            "15:15:25 |     image_mode: raw\n",
            "15:15:25 |     image_size: 256\n",
            "15:15:25 |     inference: greedy\n",
            "15:15:25 |     init_model: parlai/gpt-2-small-spectrum.checkpoint\n",
            "15:15:25 |     init_opt: None\n",
            "15:15:25 |     interactive_mode: False\n",
            "15:15:25 |     invsqrt_lr_decay_gamma: -1\n",
            "15:15:25 |     is_debug: False\n",
            "15:15:25 |     label_truncate: 256\n",
            "15:15:25 |     lambda_decay: 0.9\n",
            "15:15:25 |     learningrate: 1\n",
            "15:15:25 |     log_every_n_secs: -1\n",
            "15:15:25 |     log_every_n_steps: 50\n",
            "15:15:25 |     log_keep_fields: all\n",
            "15:15:25 |     loglevel: info\n",
            "15:15:25 |     lr_scheduler: reduceonplateau\n",
            "15:15:25 |     lr_scheduler_decay: 0.5\n",
            "15:15:25 |     lr_scheduler_patience: 3\n",
            "15:15:25 |     max_train_steps: -1\n",
            "15:15:25 |     max_train_time: -1\n",
            "15:15:25 |     metrics: ppl,f1,accuracy,rouge,bleu\n",
            "15:15:25 |     model: hugging_face/gpt2\n",
            "15:15:25 |     model_file: parlai/gpt-2-small-spectrum\n",
            "15:15:25 |     model_name: None\n",
            "15:15:25 |     momentum: 0\n",
            "15:15:25 |     multitask_weights: [1]\n",
            "15:15:25 |     mutators: None\n",
            "15:15:25 |     nesterov: True\n",
            "15:15:25 |     no_cuda: False\n",
            "15:15:25 |     num_epochs: 6.0\n",
            "15:15:25 |     num_examples: -1\n",
            "15:15:25 |     num_workers: 0\n",
            "15:15:25 |     nus: [0.7]\n",
            "15:15:25 |     omega_bound: 0.3\n",
            "15:15:25 |     optimizer: sgd\n",
            "15:15:25 |     override: \"{'model_file': 'parlai/gpt-2-small-spectrum', 'task': 'gutenbergbookchars:S3', 'batchsize': 10, 'fp16': True, 'dynamic_batching': 'full', 'metrics': 'ppl,f1,accuracy,rouge,bleu', 'report_filename': 's3-gpt2-small.json'}\"\n",
            "15:15:25 |     p_reset: True\n",
            "15:15:25 |     parlai_home: /usr/local/lib/python3.8/dist-packages\n",
            "15:15:25 |     person_tokens: False\n",
            "15:15:25 |     rank_candidates: False\n",
            "15:15:25 |     report_filename: s3-gpt2-small.json\n",
            "15:15:25 |     save_after_valid: True\n",
            "15:15:25 |     save_every_n_secs: -1\n",
            "15:15:25 |     save_format: conversations\n",
            "15:15:25 |     seed: None\n",
            "15:15:25 |     short_final_eval: False\n",
            "15:15:25 |     skip_generation: False\n",
            "15:15:25 |     special_tok_lst: None\n",
            "15:15:25 |     split_lines: False\n",
            "15:15:25 |     starttime: Aug14_17-53\n",
            "15:15:25 |     task: gutenbergbookchars:S3\n",
            "15:15:25 |     teacher_seed: None\n",
            "15:15:25 |     temperature: 1.0\n",
            "15:15:25 |     tensorboard_log: True\n",
            "15:15:25 |     tensorboard_logdir: None\n",
            "15:15:25 |     text_truncate: 360\n",
            "15:15:25 |     topk: 10\n",
            "15:15:25 |     topp: 0.9\n",
            "15:15:25 |     truncate: -1\n",
            "15:15:25 |     update_freq: 1\n",
            "15:15:25 |     use_reply: label\n",
            "15:15:25 |     validation_cutoff: 1.0\n",
            "15:15:25 |     validation_every_n_epochs: 0.5\n",
            "15:15:25 |     validation_every_n_secs: -1\n",
            "15:15:25 |     validation_every_n_steps: -1\n",
            "15:15:25 |     validation_max_exs: -1\n",
            "15:15:25 |     validation_metric: f1\n",
            "15:15:25 |     validation_metric_mode: None\n",
            "15:15:25 |     validation_patience: 10\n",
            "15:15:25 |     validation_share_agent: False\n",
            "15:15:25 |     verbose: False\n",
            "15:15:25 |     verbose_topk: -1\n",
            "15:15:25 |     wandb_entity: None\n",
            "15:15:25 |     wandb_log: False\n",
            "15:15:25 |     wandb_log_model: False\n",
            "15:15:25 |     wandb_name: None\n",
            "15:15:25 |     wandb_project: None\n",
            "15:15:25 |     warmup_rate: 0.0001\n",
            "15:15:25 |     warmup_updates: -1\n",
            "15:15:25 |     weight_decay: None\n",
            "15:15:25 |     world_logs: \n",
            "15:15:25 | Evaluating task gutenbergbookchars:S3 using datatype valid.\n",
            "15:15:25 | creating task(s): gutenbergbookchars:S3\n",
            "15:15:25 | loading fbdialog data: /usr/local/lib/python3.8/dist-packages/data/GutenbertBookChars/valid_403_3.txt\n",
            "15:15:29 | \u001b[1mReport for gutenbergbookchars:S3:\n",
            "    accuracy  \\\n",
            "           0   \n",
            "    bleu-1  \\\n",
            "    .07469   \n",
            "    bleu-2  \\\n",
            "     .0209   \n",
            "    bleu-3  \\\n",
            "    .01026   \n",
            "    bleu-4  \\\n",
            "   .008074   \n",
            "    clen  \\\n",
            "   79.29   \n",
            "    ctpb  \\\n",
            "    1348   \n",
            "    ctps  \\\n",
            "    1426   \n",
            "    ctrunc  \\\n",
            "         0   \n",
            "    ctrunclen  \\\n",
            "            0   \n",
            "    exps  \\\n",
            "   17.98   \n",
            "    exs  \\\n",
            "     34   \n",
            "      f1  \\\n",
            "   .1187   \n",
            "    gen_n_toks  \\\n",
            "         17.74   \n",
            "    gpu_mem  \\\n",
            "      .1391   \n",
            "    llen  \\\n",
            "    37.5   \n",
            "    loss  \\\n",
            "   3.498   \n",
            "      lr  \\\n",
            "   .5000   \n",
            "    ltpb  \\\n",
            "   637.5   \n",
            "    ltps  \\\n",
            "   674.3   \n",
            "    ltrunc  \\\n",
            "         0   \n",
            "    ltrunclen  \\\n",
            "            0   \n",
            "     ppl  \\\n",
            "   33.07   \n",
            "    precision  \\\n",
            "        .1961   \n",
            "    recall  \\\n",
            "     .1035   \n",
            "    rouge_1  \\\n",
            "      .1076   \n",
            "    rouge_2  \\\n",
            "     .01696   \n",
            "    rouge_L  \\\n",
            "     .09904   \n",
            "    token_acc  \\\n",
            "        .3263   \n",
            "    token_em  \\\n",
            "           0   \n",
            "    total_train_updates  \\\n",
            "                  20132   \n",
            "    tpb  \\\n",
            "   1986   \n",
            "    tps  \n",
            "   2100\u001b[0m\n",
            "15:15:29 | Finished evaluating tasks ['gutenbergbookchars:S3'] using datatype valid\n",
            "    accuracy  \\\n",
            "           0   \n",
            "    bleu-1  \\\n",
            "    .07469   \n",
            "    bleu-2  \\\n",
            "     .0209   \n",
            "    bleu-3  \\\n",
            "    .01026   \n",
            "    bleu-4  \\\n",
            "   .008074   \n",
            "    clen  \\\n",
            "   79.29   \n",
            "    ctpb  \\\n",
            "    1348   \n",
            "    ctps  \\\n",
            "    1426   \n",
            "    ctrunc  \\\n",
            "         0   \n",
            "    ctrunclen  \\\n",
            "            0   \n",
            "    exps  \\\n",
            "   17.98   \n",
            "    exs  \\\n",
            "     34   \n",
            "      f1  \\\n",
            "   .1187   \n",
            "    gen_n_toks  \\\n",
            "         17.74   \n",
            "    gpu_mem  \\\n",
            "      .1391   \n",
            "    llen  \\\n",
            "    37.5   \n",
            "    loss  \\\n",
            "   3.498   \n",
            "      lr  \\\n",
            "   .5000   \n",
            "    ltpb  \\\n",
            "   637.5   \n",
            "    ltps  \\\n",
            "   674.3   \n",
            "    ltrunc  \\\n",
            "         0   \n",
            "    ltrunclen  \\\n",
            "            0   \n",
            "     ppl  \\\n",
            "   33.07   \n",
            "    precision  \\\n",
            "        .1961   \n",
            "    recall  \\\n",
            "     .1035   \n",
            "    rouge_1  \\\n",
            "      .1076   \n",
            "    rouge_2  \\\n",
            "     .01696   \n",
            "    rouge_L  \\\n",
            "     .09904   \n",
            "    token_acc  \\\n",
            "        .3263   \n",
            "    token_em  \\\n",
            "           0   \n",
            "    total_train_updates  \\\n",
            "                  20132   \n",
            "    tpb  \\\n",
            "   1986   \n",
            "    tps  \n",
            "   2100\n",
            "15:15:29 | Saving model report to s3-gpt2-small.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!parlai eval_model -mf parlai/gpt-2-small-spectrum \\\n",
        "  -t gutenbergbookchars:S4 -bs 10 \\\n",
        "  --fp16 True --dynamic-batching full --metrics ppl,f1,accuracy,rouge,bleu \\\n",
        "  --report-filename \"s4-gpt2-small.json\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSpj10X-8BTG",
        "outputId": "23573a56-a827-43ea-c0bc-d5c2ead6b1c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15:15:10 | \u001b[33mWARNING: this model is in beta and the API is subject to change.\u001b[0m\n",
            "15:15:10 | \u001b[33mOverriding opt[\"task\"] to gutenbergbookchars:S4 (previously: gutenbergbookchars:Spectrum)\u001b[0m\n",
            "15:15:10 | \u001b[33mOverriding opt[\"batchsize\"] to 10 (previously: 8)\u001b[0m\n",
            "15:15:10 | \u001b[33mOverriding opt[\"metrics\"] to ppl,f1,accuracy,rouge,bleu (previously: default)\u001b[0m\n",
            "15:15:10 | Using CUDA\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50260. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "15:15:14 | Total parameters: 124,442,112 (124,442,112 trainable)\n",
            "15:15:14 | Loading existing model params from parlai/gpt-2-small-spectrum\n",
            "15:15:14 | Opt:\n",
            "15:15:14 |     adafactor_eps: '[1e-30, 0.001]'\n",
            "15:15:14 |     adam_eps: 1e-08\n",
            "15:15:14 |     add_p1_after_newln: False\n",
            "15:15:14 |     add_special_tokens: True\n",
            "15:15:14 |     add_start_token: True\n",
            "15:15:14 |     aggregate_micro: False\n",
            "15:15:14 |     allow_missing_init_opts: False\n",
            "15:15:14 |     area_under_curve_class: None\n",
            "15:15:14 |     area_under_curve_digits: -1\n",
            "15:15:14 |     batchsize: 10\n",
            "15:15:14 |     beam_block_full_context: True\n",
            "15:15:14 |     beam_block_list_filename: None\n",
            "15:15:14 |     beam_block_ngram: -1\n",
            "15:15:14 |     beam_context_block_ngram: -1\n",
            "15:15:14 |     beam_delay: 30\n",
            "15:15:14 |     beam_length_penalty: 0.65\n",
            "15:15:14 |     beam_min_length: 1\n",
            "15:15:14 |     beam_size: 1\n",
            "15:15:14 |     betas: '[0.9, 0.999]'\n",
            "15:15:14 |     bpe_add_prefix_space: None\n",
            "15:15:14 |     bpe_debug: False\n",
            "15:15:14 |     bpe_dropout: None\n",
            "15:15:14 |     bpe_merge: None\n",
            "15:15:14 |     bpe_vocab: None\n",
            "15:15:14 |     clearml_log: False\n",
            "15:15:14 |     clearml_project_name: ParlAI\n",
            "15:15:14 |     clearml_task_name: 'Default Task'\n",
            "15:15:14 |     compute_tokenized_bleu: False\n",
            "15:15:14 |     datapath: /usr/local/lib/python3.8/dist-packages/data\n",
            "15:15:14 |     datatype: train\n",
            "15:15:14 |     delimiter: '\\n'\n",
            "15:15:14 |     dict_class: parlai.agents.hugging_face.dict:Gpt2DictionaryAgent\n",
            "15:15:14 |     dict_endtoken: __end__\n",
            "15:15:14 |     dict_file: parlai/gpt-2-small-spectrum.dict\n",
            "15:15:14 |     dict_include_test: False\n",
            "15:15:14 |     dict_include_valid: False\n",
            "15:15:14 |     dict_initpath: None\n",
            "15:15:14 |     dict_language: english\n",
            "15:15:14 |     dict_lower: False\n",
            "15:15:14 |     dict_max_ngram_size: -1\n",
            "15:15:14 |     dict_maxexs: 0\n",
            "15:15:14 |     dict_maxtokens: -1\n",
            "15:15:14 |     dict_minfreq: 0\n",
            "15:15:14 |     dict_nulltoken: __null__\n",
            "15:15:14 |     dict_starttoken: __start__\n",
            "15:15:14 |     dict_textfields: text,labels\n",
            "15:15:14 |     dict_tokenizer: re\n",
            "15:15:14 |     dict_unktoken: __unk__\n",
            "15:15:14 |     display_examples: False\n",
            "15:15:14 |     download_path: None\n",
            "15:15:14 |     dynamic_batching: full\n",
            "15:15:14 |     embedding_projection: random\n",
            "15:15:14 |     embedding_type: random\n",
            "15:15:14 |     eval_batchsize: None\n",
            "15:15:14 |     eval_dynamic_batching: None\n",
            "15:15:14 |     evaltask: None\n",
            "15:15:14 |     final_extra_opt: \n",
            "15:15:14 |     force_fp16_tokens: True\n",
            "15:15:14 |     fp16: True\n",
            "15:15:14 |     fp16_impl: safe\n",
            "15:15:14 |     gpt2_size: small\n",
            "15:15:14 |     gpu: -1\n",
            "15:15:14 |     gpu_beam_blocking: False\n",
            "15:15:14 |     gradient_clip: 0.1\n",
            "15:15:14 |     hide_labels: False\n",
            "15:15:14 |     history_add_global_end_token: None\n",
            "15:15:14 |     history_reversed: False\n",
            "15:15:14 |     history_size: -1\n",
            "15:15:14 |     image_cropsize: 224\n",
            "15:15:14 |     image_mode: raw\n",
            "15:15:14 |     image_size: 256\n",
            "15:15:14 |     inference: greedy\n",
            "15:15:14 |     init_model: parlai/gpt-2-small-spectrum.checkpoint\n",
            "15:15:14 |     init_opt: None\n",
            "15:15:14 |     interactive_mode: False\n",
            "15:15:14 |     invsqrt_lr_decay_gamma: -1\n",
            "15:15:14 |     is_debug: False\n",
            "15:15:14 |     label_truncate: 256\n",
            "15:15:14 |     lambda_decay: 0.9\n",
            "15:15:14 |     learningrate: 1\n",
            "15:15:14 |     log_every_n_secs: -1\n",
            "15:15:14 |     log_every_n_steps: 50\n",
            "15:15:14 |     log_keep_fields: all\n",
            "15:15:14 |     loglevel: info\n",
            "15:15:14 |     lr_scheduler: reduceonplateau\n",
            "15:15:14 |     lr_scheduler_decay: 0.5\n",
            "15:15:14 |     lr_scheduler_patience: 3\n",
            "15:15:14 |     max_train_steps: -1\n",
            "15:15:14 |     max_train_time: -1\n",
            "15:15:14 |     metrics: ppl,f1,accuracy,rouge,bleu\n",
            "15:15:14 |     model: hugging_face/gpt2\n",
            "15:15:14 |     model_file: parlai/gpt-2-small-spectrum\n",
            "15:15:14 |     model_name: None\n",
            "15:15:14 |     momentum: 0\n",
            "15:15:14 |     multitask_weights: [1]\n",
            "15:15:14 |     mutators: None\n",
            "15:15:14 |     nesterov: True\n",
            "15:15:14 |     no_cuda: False\n",
            "15:15:14 |     num_epochs: 6.0\n",
            "15:15:14 |     num_examples: -1\n",
            "15:15:14 |     num_workers: 0\n",
            "15:15:14 |     nus: [0.7]\n",
            "15:15:14 |     omega_bound: 0.3\n",
            "15:15:14 |     optimizer: sgd\n",
            "15:15:14 |     override: \"{'model_file': 'parlai/gpt-2-small-spectrum', 'task': 'gutenbergbookchars:S4', 'batchsize': 10, 'fp16': True, 'dynamic_batching': 'full', 'metrics': 'ppl,f1,accuracy,rouge,bleu', 'report_filename': 's4-gpt2-small.json'}\"\n",
            "15:15:14 |     p_reset: True\n",
            "15:15:14 |     parlai_home: /usr/local/lib/python3.8/dist-packages\n",
            "15:15:14 |     person_tokens: False\n",
            "15:15:14 |     rank_candidates: False\n",
            "15:15:14 |     report_filename: s4-gpt2-small.json\n",
            "15:15:14 |     save_after_valid: True\n",
            "15:15:14 |     save_every_n_secs: -1\n",
            "15:15:14 |     save_format: conversations\n",
            "15:15:14 |     seed: None\n",
            "15:15:14 |     short_final_eval: False\n",
            "15:15:14 |     skip_generation: False\n",
            "15:15:14 |     special_tok_lst: None\n",
            "15:15:14 |     split_lines: False\n",
            "15:15:14 |     starttime: Aug14_17-53\n",
            "15:15:14 |     task: gutenbergbookchars:S4\n",
            "15:15:14 |     teacher_seed: None\n",
            "15:15:14 |     temperature: 1.0\n",
            "15:15:14 |     tensorboard_log: True\n",
            "15:15:14 |     tensorboard_logdir: None\n",
            "15:15:14 |     text_truncate: 360\n",
            "15:15:14 |     topk: 10\n",
            "15:15:14 |     topp: 0.9\n",
            "15:15:14 |     truncate: -1\n",
            "15:15:14 |     update_freq: 1\n",
            "15:15:14 |     use_reply: label\n",
            "15:15:14 |     validation_cutoff: 1.0\n",
            "15:15:14 |     validation_every_n_epochs: 0.5\n",
            "15:15:14 |     validation_every_n_secs: -1\n",
            "15:15:14 |     validation_every_n_steps: -1\n",
            "15:15:14 |     validation_max_exs: -1\n",
            "15:15:14 |     validation_metric: f1\n",
            "15:15:14 |     validation_metric_mode: None\n",
            "15:15:14 |     validation_patience: 10\n",
            "15:15:14 |     validation_share_agent: False\n",
            "15:15:14 |     verbose: False\n",
            "15:15:14 |     verbose_topk: -1\n",
            "15:15:14 |     wandb_entity: None\n",
            "15:15:14 |     wandb_log: False\n",
            "15:15:14 |     wandb_log_model: False\n",
            "15:15:14 |     wandb_name: None\n",
            "15:15:14 |     wandb_project: None\n",
            "15:15:14 |     warmup_rate: 0.0001\n",
            "15:15:14 |     warmup_updates: -1\n",
            "15:15:14 |     weight_decay: None\n",
            "15:15:14 |     world_logs: \n",
            "15:15:14 | Evaluating task gutenbergbookchars:S4 using datatype valid.\n",
            "15:15:14 | creating task(s): gutenbergbookchars:S4\n",
            "15:15:14 | loading fbdialog data: /usr/local/lib/python3.8/dist-packages/data/GutenbertBookChars/valid_507_3.txt\n",
            "15:15:18 | \u001b[1mReport for gutenbergbookchars:S4:\n",
            "    accuracy  \\\n",
            "           0   \n",
            "    bleu-1  \\\n",
            "    .08979   \n",
            "    bleu-2  \\\n",
            "    .02101   \n",
            "    bleu-3  \\\n",
            "   .005425   \n",
            "      bleu-4  \\\n",
            "   4.828e-06   \n",
            "    clen  \\\n",
            "   101.1   \n",
            "    ctpb  \\\n",
            "    1870   \n",
            "    ctps  \\\n",
            "    1948   \n",
            "    ctrunc  \\\n",
            "         0   \n",
            "    ctrunclen  \\\n",
            "            0   \n",
            "    exps  \\\n",
            "   19.27   \n",
            "    exs  \\\n",
            "     37   \n",
            "      f1  \\\n",
            "   .1612   \n",
            "    gen_n_toks  \\\n",
            "         19.03   \n",
            "    gpu_mem  \\\n",
            "      .1342   \n",
            "    llen  \\\n",
            "   40.95   \n",
            "    loss  \\\n",
            "   3.477   \n",
            "      lr  \\\n",
            "   .5000   \n",
            "    ltpb  \\\n",
            "   757.5   \n",
            "    ltps  \\\n",
            "   788.9   \n",
            "    ltrunc  \\\n",
            "         0   \n",
            "    ltrunclen  \\\n",
            "            0   \n",
            "     ppl  \\\n",
            "   32.36   \n",
            "    precision  \\\n",
            "        .2584   \n",
            "    recall  \\\n",
            "     .1355   \n",
            "    rouge_1  \\\n",
            "      .1404   \n",
            "    rouge_2  \\\n",
            "     .01676   \n",
            "    rouge_L  \\\n",
            "      .1206   \n",
            "    token_acc  \\\n",
            "        .3432   \n",
            "    token_em  \\\n",
            "           0   \n",
            "    total_train_updates  \\\n",
            "                  20132   \n",
            "    tpb  \\\n",
            "   2628   \n",
            "    tps  \n",
            "   2737\u001b[0m\n",
            "15:15:18 | Finished evaluating tasks ['gutenbergbookchars:S4'] using datatype valid\n",
            "    accuracy  \\\n",
            "           0   \n",
            "    bleu-1  \\\n",
            "    .08979   \n",
            "    bleu-2  \\\n",
            "    .02101   \n",
            "    bleu-3  \\\n",
            "   .005425   \n",
            "      bleu-4  \\\n",
            "   4.828e-06   \n",
            "    clen  \\\n",
            "   101.1   \n",
            "    ctpb  \\\n",
            "    1870   \n",
            "    ctps  \\\n",
            "    1948   \n",
            "    ctrunc  \\\n",
            "         0   \n",
            "    ctrunclen  \\\n",
            "            0   \n",
            "    exps  \\\n",
            "   19.27   \n",
            "    exs  \\\n",
            "     37   \n",
            "      f1  \\\n",
            "   .1612   \n",
            "    gen_n_toks  \\\n",
            "         19.03   \n",
            "    gpu_mem  \\\n",
            "      .1342   \n",
            "    llen  \\\n",
            "   40.95   \n",
            "    loss  \\\n",
            "   3.477   \n",
            "      lr  \\\n",
            "   .5000   \n",
            "    ltpb  \\\n",
            "   757.5   \n",
            "    ltps  \\\n",
            "   788.9   \n",
            "    ltrunc  \\\n",
            "         0   \n",
            "    ltrunclen  \\\n",
            "            0   \n",
            "     ppl  \\\n",
            "   32.36   \n",
            "    precision  \\\n",
            "        .2584   \n",
            "    recall  \\\n",
            "     .1355   \n",
            "    rouge_1  \\\n",
            "      .1404   \n",
            "    rouge_2  \\\n",
            "     .01676   \n",
            "    rouge_L  \\\n",
            "      .1206   \n",
            "    token_acc  \\\n",
            "        .3432   \n",
            "    token_em  \\\n",
            "           0   \n",
            "    total_train_updates  \\\n",
            "                  20132   \n",
            "    tpb  \\\n",
            "   2628   \n",
            "    tps  \n",
            "   2737\n",
            "15:15:18 | Saving model report to s4-gpt2-small.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!parlai eval_model -mf parlai/gpt-2-small-spectrum \\\n",
        "  -t gutenbergbookchars:S5 -bs 10 \\\n",
        "  --fp16 True --dynamic-batching full --metrics ppl,f1,accuracy,rouge,bleu \\\n",
        "  --report-filename \"s5-gpt2-small.json\""
      ],
      "metadata": {
        "id": "RPzjFbXl8BtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "m0Duunze6MA_"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V100",
      "authorship_tag": "ABX9TyNB+lZpNVHjjzsEFXW7F6oF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}